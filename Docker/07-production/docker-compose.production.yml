# Production Docker Compose Setup
# Complete production-ready configuration with all best practices

version: "3.8"

services:
  # ================================
  # Nginx - Load Balancer/Reverse Proxy
  # ================================
  nginx:
    image: nginx:1.25-alpine
    container_name: nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/conf.d:/etc/nginx/conf.d:ro
      - ./ssl:/etc/nginx/ssl:ro
      - static-files:/usr/share/nginx/html:ro
      - nginx-logs:/var/log/nginx
    networks:
      - frontend
    depends_on:
      - app
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: 512M
        reservations:
          cpus: "0.5"
          memory: 256M
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--no-verbose",
          "--tries=1",
          "--spider",
          "http://localhost/health",
        ]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=nginx,environment=production"

  # ================================
  # Application - Node.js API
  # ================================
  app:
    image: ${DOCKER_REGISTRY}/myapp:${VERSION}
    container_name: app
    # Security
    user: "1001:1001"
    read_only: true
    tmpfs:
      - /tmp
      - /app/cache
    cap_drop:
      - ALL
    cap_add:
      - NET_BIND_SERVICE
    security_opt:
      - no-new-privileges:true
    # Environment
    environment:
      NODE_ENV: production
      DB_HOST: postgres
      DB_PORT: 5432
      DB_NAME: ${DB_NAME}
      REDIS_URL: redis://redis:6379
      LOG_LEVEL: info
    # Secrets
    secrets:
      - db_password
      - jwt_secret
      - api_key
    # Volumes
    volumes:
      - app-uploads:/app/uploads
      - app-logs:/app/logs
    # Networks
    networks:
      - frontend
      - backend
    # Dependencies
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    # Restart policy
    restart: unless-stopped
    # Resource limits
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: "2"
          memory: 2G
        reservations:
          cpus: "1"
          memory: 1G
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
    # Health check
    healthcheck:
      test: ["CMD", "node", "healthcheck.js"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    # Logging
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=app,environment=production"

  # ================================
  # Background Worker
  # ================================
  worker:
    image: ${DOCKER_REGISTRY}/myworker:${VERSION}
    container_name: worker
    user: "1001:1001"
    read_only: true
    tmpfs:
      - /tmp
    cap_drop:
      - ALL
    security_opt:
      - no-new-privileges:true
    environment:
      NODE_ENV: production
      DB_HOST: postgres
      REDIS_URL: redis://redis:6379
      RABBITMQ_URL: amqp://rabbitmq:5672
    secrets:
      - db_password
    volumes:
      - worker-logs:/app/logs
    networks:
      - backend
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
    restart: unless-stopped
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: "1"
          memory: 1G
        reservations:
          cpus: "0.5"
          memory: 512M
    healthcheck:
      test: ["CMD", "node", "healthcheck.js"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ================================
  # PostgreSQL Database
  # ================================
  postgres:
    image: postgres:15.4-alpine
    container_name: postgres
    environment:
      POSTGRES_DB: ${DB_NAME}
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD_FILE: /run/secrets/db_password
      POSTGRES_INITDB_ARGS: "-E UTF8 --locale=en_US.UTF-8"
      PGDATA: /var/lib/postgresql/data/pgdata
    secrets:
      - db_password
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./init-scripts:/docker-entrypoint-initdb.d:ro
      - postgres-backups:/backups
    networks:
      - backend
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "2"
          memory: 4G
        reservations:
          cpus: "1"
          memory: 2G
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER} -d ${DB_NAME}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    command: >
      postgres
      -c max_connections=200
      -c shared_buffers=1GB
      -c effective_cache_size=3GB
      -c maintenance_work_mem=256MB
      -c checkpoint_completion_target=0.9
      -c wal_buffers=16MB
      -c default_statistics_target=100
      -c random_page_cost=1.1
      -c effective_io_concurrency=200
      -c work_mem=5MB
      -c min_wal_size=1GB
      -c max_wal_size=4GB

  # ================================
  # Redis Cache
  # ================================
  redis:
    image: redis:7.2-alpine
    container_name: redis
    command: >
      redis-server
      --appendonly yes
      --requirepass ${REDIS_PASSWORD}
      --maxmemory 1gb
      --maxmemory-policy allkeys-lru
      --save 60 1000
    volumes:
      - redis-data:/data
    networks:
      - backend
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: 1G
        reservations:
          cpus: "0.5"
          memory: 512M
    healthcheck:
      test:
        [
          "CMD",
          "redis-cli",
          "--no-auth-warning",
          "-a",
          "${REDIS_PASSWORD}",
          "ping",
        ]
      interval: 10s
      timeout: 3s
      retries: 3
      start_period: 10s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ================================
  # RabbitMQ Message Queue
  # ================================
  rabbitmq:
    image: rabbitmq:3.12-management-alpine
    container_name: rabbitmq
    hostname: rabbitmq
    environment:
      RABBITMQ_DEFAULT_USER: ${RABBITMQ_USER}
      RABBITMQ_DEFAULT_PASS: ${RABBITMQ_PASSWORD}
      RABBITMQ_DEFAULT_VHOST: ${RABBITMQ_VHOST}
      RABBITMQ_VM_MEMORY_HIGH_WATERMARK: 512MB
    ports:
      - "15672:15672" # Management UI (restrict in production)
    volumes:
      - rabbitmq-data:/var/lib/rabbitmq
      - ./rabbitmq/rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf:ro
    networks:
      - backend
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: 1G
        reservations:
          cpus: "0.5"
          memory: 512M
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ================================
  # Prometheus - Monitoring
  # ================================
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
      - "--storage.tsdb.retention.time=30d"
      - "--web.console.libraries=/usr/share/prometheus/console_libraries"
      - "--web.console.templates=/usr/share/prometheus/consoles"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./prometheus/alerts.yml:/etc/prometheus/alerts.yml:ro
      - prometheus-data:/prometheus
    ports:
      - "9090:9090"
    networks:
      - monitoring
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 2G
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ================================
  # Grafana - Dashboards
  # ================================
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    environment:
      GF_SECURITY_ADMIN_USER: ${GRAFANA_USER}
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD}
      GF_USERS_ALLOW_SIGN_UP: "false"
      GF_SERVER_ROOT_URL: https://grafana.example.com
      GF_INSTALL_PLUGINS: grafana-clock-panel,grafana-simple-json-datasource
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning:ro
    ports:
      - "3000:3000"
    networks:
      - monitoring
    depends_on:
      - prometheus
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ================================
  # Backup Service
  # ================================
  backup:
    image: ${DOCKER_REGISTRY}/backup-service:latest
    container_name: backup
    environment:
      BACKUP_SCHEDULE: "0 2 * * *" # Daily at 2 AM
      S3_BUCKET: ${BACKUP_S3_BUCKET}
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
    volumes:
      - postgres-data:/data/postgres:ro
      - redis-data:/data/redis:ro
      - app-uploads:/data/uploads:ro
      - ./backups:/backups
    networks:
      - backend
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

# ================================
# Volumes
# ================================
volumes:
  postgres-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /mnt/data/postgres

  postgres-backups:
    driver: local

  redis-data:
    driver: local

  rabbitmq-data:
    driver: local

  app-uploads:
    driver: local

  app-logs:
    driver: local

  worker-logs:
    driver: local

  nginx-logs:
    driver: local

  static-files:
    driver: local

  prometheus-data:
    driver: local

  grafana-data:
    driver: local

# ================================
# Networks
# ================================
networks:
  frontend:
    driver: bridge
    ipam:
      config:
        - subnet: 172.28.1.0/24

  backend:
    driver: bridge
    internal: true # No external access
    ipam:
      config:
        - subnet: 172.28.2.0/24

  monitoring:
    driver: bridge
    ipam:
      config:
        - subnet: 172.28.3.0/24

# ================================
# Secrets
# ================================
secrets:
  db_password:
    external: true
    name: postgres_password_v1

  jwt_secret:
    external: true
    name: jwt_secret_v1

  api_key:
    external: true
    name: api_key_v1
# ================================
# Usage Instructions:
# ================================
#
# 1. Create secrets:
#    echo "your_db_password" | docker secret create postgres_password_v1 -
#    echo "your_jwt_secret" | docker secret create jwt_secret_v1 -
#    echo "your_api_key" | docker secret create api_key_v1 -
#
# 2. Set environment variables:
#    export VERSION=1.0.0
#    export DOCKER_REGISTRY=registry.example.com
#    export DB_NAME=myapp_production
#    export DB_USER=admin
#    export REDIS_PASSWORD=secure_password
#    export RABBITMQ_USER=admin
#    export RABBITMQ_PASSWORD=secure_password
#    export RABBITMQ_VHOST=/production
#    export GRAFANA_USER=admin
#    export GRAFANA_PASSWORD=secure_password
#
# 3. Deploy:
#    docker compose -f docker-compose.production.yml up -d
#
# 4. Scale services:
#    docker compose -f docker-compose.production.yml up -d --scale app=5 --scale worker=3
#
# 5. View logs:
#    docker compose -f docker-compose.production.yml logs -f
#
# 6. Health check:
#    curl http://localhost/health
#
# 7. Stop and remove:
#    docker compose -f docker-compose.production.yml down





